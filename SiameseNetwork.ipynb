{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "import uuid\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, GlobalAveragePooling2D, MaxPool2D, Dropout, BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model  #the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Making required directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the directory structure for our project. Namely, three folders Anchor, Negative, Positive\n",
    "pos_path = os.path.join('data', 'positive')  \n",
    "#positive images (verification images)\n",
    "neg_path = os.path.join('data', 'negative')       \n",
    "#negative images (different from the anchor images)\n",
    "anc_path = os.path.join('data', 'anchor')        \n",
    "#input image (object to be recognized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(pos_path,exist_ok=True)\n",
    "os.makedirs(neg_path,exist_ok=True)\n",
    "os.makedirs(anc_path,exist_ok=True)\n",
    "#first, we collect the negative examples through Labelled Faces in the wild repository\n",
    "#first download the required files from the website into the working directory. Then run the cell\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if the code has ran earlier then already pre-installed directories. no need to run them again....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# will take hell__lot_time. (stop the cell after  3min or even less) will have enough images downloaded to proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, folder):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the filename from the URL\n",
    "        filename = os.path.join(folder, os.path.basename(url))\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Image downloaded: {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download image from {url}\")\n",
    "\n",
    "# Function to download images from a webpage\n",
    "def download_images_from_webpage(webpage_url, folder):\n",
    "    # Fetch HTML content\n",
    "    response = requests.get(webpage_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all image tags\n",
    "        img_tags = soup.find_all('img')\n",
    "\n",
    "        # Download each image\n",
    "        for img_tag in img_tags:\n",
    "            img_url = img_tag.get('src')\n",
    "            if img_url:\n",
    "                img_url = urljoin(webpage_url, img_url)\n",
    "                download_image(img_url, folder)\n",
    "    else:\n",
    "        print(f\"Failed to fetch webpage content from {webpage_url}\")\n",
    "\n",
    "# Specify the webpage URL and the folder to save images\n",
    "webpage_url = 'https://vis-www.cs.umass.edu/lfw/sets_1.html'\n",
    "download_folder = 'downloaded_images'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "# Download images from the webpage\n",
    "download_images_from_webpage(webpage_url, download_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating positive pair of images from the dataset link provided....logical way to pair images....if the first 10 characters of images are matching they are formed as a positive pair(with label 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_images(source_dir, dest_dir1, dest_dir2):\n",
    "    # Create destination directories if they don't exist\n",
    "    os.makedirs(dest_dir1, exist_ok=True)\n",
    "    os.makedirs(dest_dir2, exist_ok=True)\n",
    "\n",
    "    # Dictionary to store pairs of images based on the first 10 characters\n",
    "    image_pairs = {}\n",
    "\n",
    "    # Iterate through each file in the source directory\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "            # Extract the first 10 characters from the filename\n",
    "            first_10_chars = filename[:10]\n",
    "\n",
    "            # Check if the first 10 characters exist in the dictionary\n",
    "            if first_10_chars in image_pairs:\n",
    "                # Move the current file to dest_dir2\n",
    "                destination_path = os.path.join(dest_dir2, filename)\n",
    "                shutil.move(os.path.join(source_dir, filename), destination_path)\n",
    "\n",
    "                # Move the paired file to dest_dir1\n",
    "                paired_filename = image_pairs[first_10_chars]\n",
    "                paired_destination_path = os.path.join(dest_dir1, paired_filename)\n",
    "                shutil.move(os.path.join(source_dir, paired_filename), paired_destination_path)\n",
    "\n",
    "                # Remove the pair from the dictionary\n",
    "                del image_pairs[first_10_chars]\n",
    "            else:\n",
    "                # Add the first 10 characters and filename to the dictionary\n",
    "                image_pairs[first_10_chars] = filename\n",
    "\n",
    "# Example usage:\n",
    "source_directory = 'downloaded_images'\n",
    "destination_directory1 = 'p1'\n",
    "destination_directory2 = 'p2'\n",
    "\n",
    "categorize_images(source_directory, destination_directory1, destination_directory2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# friends\n",
    "# like if you want to add more negative pictures taken from them camera....\n",
    "# if you have friends around___take their pictures........if you are alone___then just move out of the frame and take lesser pics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hold 'a' to capture multiple shots\n",
    "# press 'q' to quit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"captured_images_friends\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Find the latest image index in the directory\n",
    "latest_index = max([0] + [int(filename.split(\"_\")[2].split(\".\")[0]) for filename in os.listdir(save_directory) if filename.startswith(\"captured_image\")])\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is successfully captured\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Crop the frame to the region (0:500, 0:500)\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Crop the same pixels but orient it towards the center-top\n",
    "    cropped_frame = frame[0:500, (width-500)//2:(width+500)//2]\n",
    "\n",
    "\n",
    "    # Display the cropped frame\n",
    "    cv2.imshow(\"Cropped Frame\", cropped_frame)\n",
    "    #collecting images\n",
    "    if(cv2.waitKey(1) & 0XFF == ord('a')):\n",
    "        imgname = os.path.join(save_directory, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, cropped_frame)\n",
    "    # Check for 'q' key press to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        # Save the cropped frame with an incremented index to the directory\n",
    "        image_index = latest_index + 1\n",
    "        image_path = os.path.join(save_directory, f\"captured_image_{image_index}.png\")\n",
    "        cv2.imwrite(image_path, cropped_frame)\n",
    "        \n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !! this is for additional images.....like taking the pictures in different orientations and different lightings \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take atleast 22 images....hold 'a' to store a lot of screen captures at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"captured_images\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "latest_index = max([0] + [int(filename.split(\"_\")[2].split(\".\")[0]) for filename in os.listdir(save_directory) if filename.startswith(\"captured_image\")])\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "    height, width, _ = frame.shape\n",
    "    cropped_frame = frame[0:500, (width-500)//2:(width+500)//2]\n",
    "    cv2.imshow(\"Cropped Frame\", cropped_frame)\n",
    "    # Check for 'q' key press to exit\n",
    "    if(cv2.waitKey(1) & 0XFF == ord('a')):\n",
    "        imgname = os.path.join(save_directory, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, cropped_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        # Save the cropped frame with an incremented index to the directory\n",
    "        image_index = latest_index + 1\n",
    "        image_path = os.path.join(save_directory, f\"captured_image_{image_index}.png\")\n",
    "        cv2.imwrite(image_path, cropped_frame)\n",
    "        \n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1 of making positive pairs with all types of combination of the above images.\n",
    "# making a directory containing the same positive pair but in different order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = \"captured_images\"\n",
    "output_directory = \"captured_images_2\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# List all files in the input directory\n",
    "file_list = [filename for filename in os.listdir(input_directory) if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "# Iterate through each file in the input directory\n",
    "for filename in tqdm(file_list, desc=\"Processing images\", unit=\"image\"):\n",
    "    # Construct the full path of the input image\n",
    "    input_image_path = os.path.join(input_directory, filename)\n",
    "\n",
    "    try:\n",
    "        # Open the image using PIL\n",
    "        with Image.open(input_image_path) as img:\n",
    "            # Generate 22 copies of the image\n",
    "            for i in range(22):\n",
    "                # Construct the filename for the output image\n",
    "                output_filename = f\"{os.path.splitext(filename)[0]}_{i + 1}.jpg\"\n",
    "                output_image_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "                # Save the copied image to the output directory\n",
    "                img.save(output_image_path)\n",
    "    except (OSError, UnidentifiedImageError):\n",
    "        print(f\"Skipped non-image file: {filename}\")\n",
    "\n",
    "print(f\"Processed {len(file_list)} images. Created {len(file_list) * 22} images in {output_directory}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (100, 100)\n",
    "# Create the target directory if it doesn't exist\n",
    "os.makedirs(neg_path, exist_ok=True)\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw', directory)):\n",
    "        EX_PATH = os.path.join('lfw', directory, file)\n",
    "        NEW_PATH = os.path.join(neg_path, file)\n",
    "        # Open the image\n",
    "        with Image.open(EX_PATH) as img:\n",
    "            # Resize the image\n",
    "            img_resized = img.resize(target_size)\n",
    "            # Save the resized image to the target directory\n",
    "            img_resized.save(NEW_PATH)\n",
    "        # Remove the original image (optional)\n",
    "        os.remove(EX_PATH)\n",
    "\"\"\"\n",
    "first we loop over every sub directory in the lfw folder. Then for every file in each sub directory, we get the path of the file, create a new path for the\n",
    "file and the replace the two paths (in effect cutting the files from the initial location to the final location)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Writing a function to capture User's image through the webcam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is the real capture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#However, the resolution is large and needs to be reduced for processing\n",
    "#for this we make a change to the original image capturing function\n",
    "#capturing the anchor and the positive images using our webcam and opencv\n",
    "#step1. establish a connection to the webcam using VideoCapture()\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = frame[50:650, 600:1000, :]  #arbitrary values\n",
    "    #collecting anchor images\n",
    "    if(cv2.waitKey(1) & 0XFF == ord('a')):\n",
    "        imgname = os.path.join(anc_path, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "\n",
    "    #collecting positive images\n",
    "    if(cv2.waitKey(1) & 0XFF == ord('p')):\n",
    "        imgname = os.path.join(pos_path, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "\n",
    "    cv2.imshow(\"Image Collection\", frame)\n",
    "    if(cv2.waitKey(1) & 0XFF == ord('q')):\n",
    "        break\n",
    "#Release the webcam and destroy the image show frame\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(False)\n",
    "plt.show()\n",
    "#this is actually the last frame captured by the camera before i pressed q (as soon as it is pressed, the image capture stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desired size for resizing\n",
    "resize_width = 200\n",
    "resize_height = 150\n",
    "\n",
    "# Assuming 'frame' is the variable that contains the image\n",
    "# Resize the frame to the desired dimensions\n",
    "frame_resized = cv2.resize(frame, (resize_width, resize_height))\n",
    "\n",
    "# Save the resized frame as an anchor image\n",
    "imgname = os.path.join(anc_path, '{}.jpg'.format(uuid.uuid1()))\n",
    "cv2.imwrite(imgname, frame_resized)\n",
    "print(\"Anchor image saved:\", imgname)\n",
    "\n",
    "# Save the resized frame as a positive image\n",
    "imgname = os.path.join(pos_path, '{}.jpg'.format(uuid.uuid1()))\n",
    "cv2.imwrite(imgname, frame_resized)\n",
    "print(\"Positive image saved:\", imgname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(False)\n",
    "plt.show()\n",
    "#last image captured by the camera. Also, in this case, the resolution is smaller than the pervious case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(img, num_augmentations=5):\n",
    "    augmented_data = []\n",
    "\n",
    "    for i in range(num_augmentations):\n",
    "        img_aug = img\n",
    "\n",
    "        # Apply random transformations\n",
    "        img_aug = tf.image.stateless_random_brightness(img_aug, max_delta=0.02, seed=(1, 2))\n",
    "        img_aug = tf.image.stateless_random_contrast(img_aug, lower=0.6, upper=1, seed=(1, 3))\n",
    "        img_aug = tf.image.stateless_random_flip_left_right(img_aug, seed=(np.random.randint(100), np.random.randint(100)))\n",
    "        img_aug = tf.image.stateless_random_jpeg_quality(img_aug, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100), np.random.randint(100)))\n",
    "        img_aug = tf.image.stateless_random_saturation(img_aug, lower=0.9, upper=1, seed=(np.random.randint(100), np.random.randint(100)))\n",
    "\n",
    "        augmented_data.append(img_aug)\n",
    "\n",
    "    return augmented_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(pos_path):\n",
    "    img_path = os.path.join(pos_path, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is not None:\n",
    "        augmented_images = data_aug(img)\n",
    "\n",
    "        # Use the original filename with an index to avoid overwriting\n",
    "        base_file_name, file_extension = os.path.splitext(file_name)\n",
    "        \n",
    "        for idx, augmented_image in enumerate(augmented_images):\n",
    "            new_file_name = '{}_aug_{}{}'.format(base_file_name, idx, file_extension)\n",
    "            new_img_path = os.path.join(pos_path, new_file_name)\n",
    "            \n",
    "            # Save the augmented image\n",
    "            cv2.imwrite(new_img_path, augmented_image.numpy().astype(np.uint8))\n",
    "\n",
    "\n",
    "            # Check if the file exists\n",
    "            if os.path.exists(new_img_path):\n",
    "                print(f\"Successfully saved: {new_img_path}\")\n",
    "            else:\n",
    "                print(f\"Error: Failed to save {new_img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(anc_path):\n",
    "    img_path = os.path.join(anc_path, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is not None:\n",
    "        augmented_images = data_aug(img)\n",
    "\n",
    "        # Use the original filename with an index to avoid overwriting\n",
    "        base_file_name, file_extension = os.path.splitext(file_name)\n",
    "        \n",
    "        for idx, augmented_image in enumerate(augmented_images):\n",
    "            new_file_name = '{}_aug_{}{}'.format(base_file_name, idx, file_extension)\n",
    "            new_img_path = os.path.join(anc_path, new_file_name)\n",
    "            \n",
    "            # Save the augmented image\n",
    "            cv2.imwrite(new_img_path, augmented_image.numpy().astype(np.uint8))\n",
    "\n",
    "\n",
    "            # Check if the file exists\n",
    "            if os.path.exists(new_img_path):\n",
    "                print(f\"Successfully saved: {new_img_path}\")\n",
    "            else:\n",
    "                print(f\"Error: Failed to save {new_img_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Image Preprocessing for the Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting the image directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(anc_path +\"/*.jpg\").take(500)\n",
    "positive = tf.data.Dataset.list_files(pos_path +\"/*.jpg\").take(500)\n",
    "negative = tf.data.Dataset.list_files(neg_path +\"/*.jpg\").take(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_1_path = os.path.join('p1')\n",
    "positive_2_path=os.path.join('p2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding some more data.....like labelling the similar datasets to be 1 and different datasets to be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = sorted(tf.io.gfile.glob(os.path.join(positive_1_path, '*.jpg')))\n",
    "# Use from_tensor_slices to maintain order\n",
    "positive_1 = tf.data.Dataset.from_tensor_slices(file_paths).take(1000)\n",
    "file_paths2 = sorted(tf.io.gfile.glob(os.path.join(positive_2_path, '*.jpg')))\n",
    "# Use from_tensor_slices to maintain order\n",
    "positive_2 = tf.data.Dataset.from_tensor_slices(file_paths2).take(1000)\n",
    "# positive_1=tf.data.Dataset.list_files(file_paths+\"/*.jpg\").take(500)\n",
    "file_paths_mine = sorted(tf.io.gfile.glob(os.path.join(\"captured_images\", '*.jpg')))\n",
    "positive_mine=tf.data.Dataset.from_tensor_slices(file_paths_mine).take(500)\n",
    "# positive_2=tf.data.Dataset.list_files(file_paths2+\"/*.jpg\").take(500)\n",
    "file_paths_mine2 = sorted(tf.io.gfile.glob(os.path.join(\"captured_images_2\", '*.jpg')))\n",
    "positive_mine2 = tf.data.Dataset.from_tensor_slices(file_paths_mine2).take(500)\n",
    "# file_paths_friends=sorted(tf.io.gfile.glob(os.path.join(\"captured_images_friends\", '*.png')))\n",
    "# friends=tf.data.Dataset.from_tensor_slices(file_paths_friends).take(500)\n",
    "friends_path = 'captured_images_friends'\n",
    "friends = tf.data.Dataset.list_files(os.path.join(friends_path, '*.jpg')).take(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.cardinality(friends).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create a performant data pipeline, we first create a function which is mapped to the entire dataset\n",
    "def preprocess(file_path):\n",
    "    #reading in image from filepath\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (100,100))\n",
    "    img = img/255.0   #rescaling for better learning\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (anchor, positive) = 1,1,1,1,1\n",
    "# (anchor, negative) = 0,0,0,0,0\n",
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor.repeat(), negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(negative)))))\n",
    "data = positives.concatenate(negatives)\n",
    "# tf.data.experimental.cardinality(negatives).numpy()\n",
    "additional_positives=tf.data.Dataset.zip((positive_1, positive_2, tf.data.Dataset.from_tensor_slices(tf.ones(len(positive_1)))))\n",
    "data=data.concatenate(additional_positives)\n",
    "p_mine = tf.data.Dataset.zip((positive_mine.repeat(), positive_mine2, tf.data.Dataset.from_tensor_slices(tf.ones(484))))\n",
    "p_mine= p_mine.shuffle(100000)\n",
    "p_mine=p_mine.take(100)\n",
    "n_friends=tf.data.Dataset.zip((positive_mine2,friends.repeat(),tf.data.Dataset.from_tensor_slices(tf.zeros(100))))\n",
    "n_friends= n_friends.shuffle(1000)\n",
    "n_friends=n_friends.take(100)\n",
    "m_friends=tf.data.Dataset.zip((positive_mine.repeat(),friends.repeat(),tf.data.Dataset.from_tensor_slices(tf.zeros(100))))\n",
    "m_friends= m_friends.shuffle(1000)\n",
    "m_friends=m_friends.take(100)\n",
    "# # Concatenate the converted p_mine with data\n",
    "data = data.concatenate(p_mine)\n",
    "data=data.concatenate(n_friends)\n",
    "data=data.concatenate(m_friends)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the below two codes are just for viewing....if taking lot of time to load the images.....then stop the below two cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming anchor and positive are datasets with file paths to images\n",
    "# data is your concatenated dataset\n",
    "# Iterate through the positive pairs in the dataset\n",
    "for anchor_path, positive_path, label in data:\n",
    "    # Check if the pair is a positive pair (label=1)\n",
    "    if label.numpy() == 1:\n",
    "        # Load images from file paths\n",
    "        anchor_img = Image.open(anchor_path.numpy().decode())\n",
    "        positive_img = Image.open(positive_path.numpy().decode())\n",
    "\n",
    "        # Display the images\n",
    "        plt.figure()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(anchor_img)\n",
    "        plt.title('Anchor Image')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(positive_img)\n",
    "        plt.title('Positive Image')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming anchor and positive are datasets with file paths to images\n",
    "# data is your concatenated dataset\n",
    "# Iterate through the positive pairs in the dataset\n",
    "for anchor_path, negative_path, label in data:\n",
    "    # Check if the pair is a positive pair (label=1)\n",
    "    if label.numpy() == 0:\n",
    "        # Load images from file paths\n",
    "        anchor_img = Image.open(anchor_path.numpy().decode())\n",
    "        negative_img = Image.open(negative_path.numpy().decode())\n",
    "\n",
    "        # Display the images\n",
    "        plt.figure()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(anchor_img)\n",
    "        plt.title('Anchor Image')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(negative_img)\n",
    "        plt.title('negative Image')\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing what is happening\n",
    "sample = data.as_numpy_iterator()\n",
    "sample.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return (preprocess(input_img), preprocess(validation_img), label)\n",
    "\n",
    "res = preprocess_twin(*sample.next())\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(res[0])\n",
    "plt.axis(False)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(res[1])\n",
    "plt.axis(False)\n",
    "\n",
    "#this is an example of anchor and (positive or negative) image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the data loader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()\n",
    "res = samples.next()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(res[0])\n",
    "plt.axis(False)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(res[1])\n",
    "plt.axis(False)\n",
    "\n",
    "#this is an example of anchor and (negative or positive) image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the entire data into training and testing data\n",
    "train_data = data.take(round(len(data)*0.7))\n",
    "# train_data = train_data.batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "test_data = data.skip(round(len(data)*0.7))\n",
    "test_data = test_data.take(round(len(data)*0.3))\n",
    "# test_data = test_data.batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "print(tf.data.experimental.cardinality(test_data).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# was facing difficulty in zip dataframe...so converted it to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming data is your dataset\n",
    "data_list = list(data.as_numpy_iterator())  # Convert the dataset to a list\n",
    "\n",
    "# Extracting anchor images, positive/negative images, and labels\n",
    "anchor_images = [item[0].flatten() for item in data_list]\n",
    "positive_or_negative_images = [item[1].flatten() for item in data_list]\n",
    "labels = [item[2] for item in data_list]\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame({'anchor_images': anchor_images, \n",
    "                   'positive_or_negative_images': positive_or_negative_images, \n",
    "                   'labels': labels})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_list = list(data.as_numpy_iterator())  \n",
    "anchor_images = [item[0] for item in data_list]\n",
    "positive_or_negative_images = [item[1] for item in data_list]\n",
    "labels = [item[2] for item in data_list]\n",
    "pairs = []\n",
    "for i in range(len(anchor_images)):\n",
    "    pairs.append((anchor_images[i], positive_or_negative_images[i], labels[i]))\n",
    "train_pairs, test_pairs = train_test_split(pairs, test_size=0.3, random_state=42)\n",
    "train_anchor_images, train_positive_or_negative_images, train_labels = zip(*train_pairs)\n",
    "test_anchor_images, test_positive_or_negative_images, test_labels = zip(*test_pairs)\n",
    "train_df = pd.DataFrame({'anchor_images': train_anchor_images, \n",
    "                         'positive_or_negative_images': train_positive_or_negative_images, \n",
    "                         'labels': train_labels})\n",
    "test_df = pd.DataFrame({'anchor_images': test_anchor_images, \n",
    "                        'positive_or_negative_images': test_positive_or_negative_images, \n",
    "                        'labels': test_labels})\n",
    "print(\"Training Data:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTesting Data:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (9, 9), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D((2, 2)),\n",
    "        Conv2D(128, (7, 7), activation='relu'),\n",
    "        MaxPool2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPool2D((2, 2)),\n",
    "        Conv2D(256, (4, 4), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "#         layers.Dense(4096, activation='relu'),\n",
    "        Dense(4096, activation='relu'),\n",
    "#         layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Specify input shape based on your image size and channels\n",
    "input_shape = (100, 100, 3)\n",
    "\n",
    "# Build the base model\n",
    "base_model = build_base_model(input_shape)\n",
    "\n",
    "# Display the model summary\n",
    "base_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Building the distance layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_distance_layer(output_anchor, output_positive):\n",
    "    distance = tf.reduce_sum(tf.abs(output_anchor - output_positive), axis=1, keepdims=True)\n",
    "    return distance\n",
    "\n",
    "# Define placeholder tensors for anchor and positive outputs\n",
    "output_anchor = Input(shape=(4096,))\n",
    "output_positive = Input(shape=(4096,))\n",
    "\n",
    "# Build the distance layer\n",
    "distance = build_distance_layer(output_anchor, output_positive)\n",
    "\n",
    "# Display the distance layer summary\n",
    "distance_model = Model(inputs=[output_anchor, output_positive], outputs=distance)\n",
    "distance_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Making the Siamese Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model(input_shape):\n",
    "    # Assuming build_base_model and build_distance_layer functions are defined\n",
    "    base_model = build_base_model(input_shape)\n",
    "\n",
    "    input_anchor = Input(shape=input_shape)\n",
    "    input_positive = Input(shape=input_shape)\n",
    "\n",
    "    output_anchor = base_model(input_anchor)\n",
    "    output_positive = base_model(input_positive)\n",
    "\n",
    "    distance = build_distance_layer(output_anchor, output_positive)\n",
    "\n",
    "#     Add a dense layer for binary classification\n",
    "    logistic_layer = Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "    siamese_model = Model(inputs=[input_anchor, input_positive], outputs=logistic_layer)\n",
    "    return siamese_model\n",
    "\n",
    "# Specify input shape based on your image size and channels\n",
    "input_shape = (100, 100, 3)\n",
    "\n",
    "# Build the siamese model\n",
    "siamese_model = build_siamese_model(input_shape)\n",
    "\n",
    "# Display the siamese model summary\n",
    "siamese_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setting up Training Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Specify input shape based on your image size and channels\n",
    "# input_shape = (100, 100, 3)\n",
    "\n",
    "# # Build the siamese model\n",
    "# siamese_model = build_siamese_model(input_shape)\n",
    "\n",
    "# Compile the model with an optimizer and a loss function\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert DataFrame columns to NumPy arrays\n",
    "train_anchor_images = np.array(train_df['anchor_images'].tolist())\n",
    "train_positive_or_negative_images = np.array(train_df['positive_or_negative_images'].tolist())\n",
    "train_labels = np.array(train_df['labels'].tolist())\n",
    "\n",
    "test_anchor_images = np.array(test_df['anchor_images'].tolist())\n",
    "test_positive_or_negative_images = np.array(test_df['positive_or_negative_images'].tolist())\n",
    "test_labels = np.array(test_df['labels'].tolist())\n",
    "\n",
    "# Now you can train the model\n",
    "siamese_model.fit(\n",
    "    [train_anchor_images, train_positive_or_negative_images],\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    validation_data=([test_anchor_images, test_positive_or_negative_images], test_labels)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Real Time test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tf.keras.metrics.Recall()\n",
    "p = tf.keras.metrics.Precision()\n",
    "a=0\n",
    "b=1\n",
    "c=0\n",
    "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
    "    # Ensure that the input data has the correct shape\n",
    "    test_input = np.expand_dims(test_input, axis=0)\n",
    "    test_val = np.expand_dims(test_val, axis=0)\n",
    "    \n",
    "    # Assuming that the images are RGB, add an extra dimension for the color channel\n",
    "    test_input = np.expand_dims(test_input, axis=-1)\n",
    "    test_val = np.expand_dims(test_val, axis=-1)\n",
    "\n",
    "    # Ensure y_true is a numpy array\n",
    "    y_true = np.array(y_true)\n",
    "\n",
    "    # Make predictions\n",
    "    yhat = siamese_model.predict([test_input, test_val])\n",
    "    print(yhat)\n",
    "    # Remove the extra dimensions from yhat\n",
    "    yhat = np.squeeze(yhat, axis=0)\n",
    "    \n",
    "    # Handle the case when y_true has an empty shape\n",
    "    if y_true.shape == ():\n",
    "        y_true = np.expand_dims(y_true, axis=0)\n",
    "    print(y_true)\n",
    "    # Ensure y_true and yhat have the same shape\n",
    "    y_true = np.reshape(y_true, yhat.shape)\n",
    "    if(y_true==1):\n",
    "        a=max(yhat,a)\n",
    "    if(y_true==0):\n",
    "        b=min(yhat,b)\n",
    "    # Update metrics\n",
    "    r.update_state(y_true, yhat)\n",
    "    p.update_state(y_true, yhat) \n",
    "\n",
    "print(\"Recall:\", r.result().numpy())\n",
    "print(\"Precision:\", p.result().numpy())\n",
    "print(\"a:\",a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_images_dir = 'application_data/verification_images'\n",
    "input_image_dir = 'application_data/input_image'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(verification_images_dir, exist_ok=True)\n",
    "os.makedirs(input_image_dir, exist_ok=True)\n",
    "\n",
    "# Verify if directories are created successfully\n",
    "print(f\"Verification images directory: {verification_images_dir}\")\n",
    "print(f\"Input image directory: {input_image_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join('application_data', 'verification_images'))\n",
    "os.path.join('application_data', 'input_image', 'input_image.jpg')\n",
    "for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
    "    validation_img = os.path.join('application_data', 'verification_images', image)\n",
    "    print(validation_img)\n",
    "def verify(model, detection_threshold, verification_threshold):\n",
    "    # Build results array\n",
    "    results = []\n",
    "    for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
    "        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))\n",
    "        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n",
    "        \n",
    "        # Make Predictions \n",
    "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
    "        results.append(result)\n",
    "    \n",
    "    # Detection Threshold: Metric above which a prediciton is considered positive \n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "    \n",
    "    # Verification Threshold: Proportion of positive predictions / total positive samples \n",
    "    verification = detection / len(os.listdir(os.path.join('application_data', 'verification_images'))) \n",
    "    verified = verification > verification_threshold\n",
    "    \n",
    "    return results, verified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## taking an input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    while True:\n",
    "        # Read a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        # Crop the same pixels but orient it towards the center-top\n",
    "        frame = frame[0:500, (width-500)//2:(width+500)//2]\n",
    "\n",
    "        # Display the captured image\n",
    "        cv2.imshow(\"Captured Image\", frame)\n",
    "\n",
    "        # Save the captured frame as an image when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            imgname = os.path.join('application_data', 'input_image', 'captured_image.jpg')\n",
    "            cv2.imwrite(imgname, frame)\n",
    "            print(\"Image captured and saved successfully.\")\n",
    "            break\n",
    "\n",
    "    # Release the webcam and destroy the image show frame\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to the input image\n",
    "input_image_path = os.path.join('application_data', 'input_image', 'captured_image.jpg')\n",
    "\n",
    "# Read the original image\n",
    "original_image = cv2.imread(input_image_path)\n",
    "\n",
    "# Resize the image to 100x100\n",
    "resized_image = cv2.resize(original_image, (100, 100))\n",
    "\n",
    "# Overwrite the original image with the resized version\n",
    "cv2.imwrite(input_image_path, resized_image)\n",
    "\n",
    "print(f\"Resized image overwritten at {input_image_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy/pasting an image from the anchor files to verification file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_dir = 'data/anchor'\n",
    "verification_dir = 'application_data/verification_images'\n",
    "\n",
    "# List all files in the 'data/anchor' directory\n",
    "all_images = os.listdir(anchor_dir)\n",
    "\n",
    "# Randomly choose one image\n",
    "random_image = random.choice(all_images)\n",
    "\n",
    "# Construct the full path for the source image\n",
    "source_path = os.path.join(anchor_dir, random_image)\n",
    "\n",
    "# Construct the full path for the destination image in 'application_data/verification_images'\n",
    "destination_path = os.path.join(verification_dir, random_image)\n",
    "\n",
    "# Copy the image from source to destination\n",
    "shutil.copyfile(source_path, destination_path)\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(destination_path)\n",
    "\n",
    "# Resize the image to 100x100\n",
    "resized_image1 = cv2.resize(image, (100, 100))\n",
    "\n",
    "# Save the resized image\n",
    "cv2.imwrite(destination_path, resized_image1)\n",
    "\n",
    "print(f\"Image '{random_image}' copied and resized to '{verification_dir}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the captured image\n",
    "captured_image = cv2.imread(os.path.join('application_data', 'input_image', 'captured_image.jpg'))\n",
    "\n",
    "# Resize the image\n",
    "resized_image = cv2.resize(captured_image, (100, 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1=cv2.imread(os.path.join('test1', 'captured_image_4.png'))\n",
    "# # Resize the image\n",
    "# resized_imoge1 = cv2.resize(test1, (100, 100))\n",
    "# test2=cv2.imread(os.path.join('test2', 'captured_image_6.png'))\n",
    "# # Resize the image\n",
    "# resized_imoge2 = cv2.resize(test2, (100, 100))\n",
    "# siamese_model.predict(\n",
    "#     [np.expand_dims(resized_imoge1, axis=0), np.expand_dims(resized_imoge2, axis=0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model, detection_threshold, verification_threshold):\n",
    "    # Build results array\n",
    "    results = []\n",
    "    input_img_path = os.path.join('application_data', 'input_image', 'captured_image.jpg')\n",
    "\n",
    "    if os.path.isfile(input_img_path):\n",
    "        # Read the input image\n",
    "        input_img = preprocess(input_img_path)\n",
    "\n",
    "        # List only image files in 'application_data/verification_images'\n",
    "        verification_images = [\n",
    "            os.path.join('application_data', 'verification_images', image)\n",
    "            for image in os.listdir(os.path.join('application_data', 'verification_images'))\n",
    "            if image.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))\n",
    "        ]\n",
    "\n",
    "       \n",
    "\n",
    "        for validation_img_path in verification_images:\n",
    "            validation_img = preprocess(validation_img_path)\n",
    "\n",
    "            # Make Predictions\n",
    "            result = model.predict([np.expand_dims(input_img, axis=0), np.expand_dims(validation_img, axis=0)])\n",
    "            results.append(result[0][0])  # Assuming model output shape is (batch_size, 1)\n",
    "\n",
    "        # Debugging: Print results\n",
    "        print(\"Verification Results:\", results)\n",
    "\n",
    "        # Detection Threshold: Metric above which a prediction is considered positive\n",
    "        detection = np.sum(np.array(results) > detection_threshold)\n",
    "        print(np.sum(np.array(results)))\n",
    "        # Verification Threshold: Proportion of positive predictions / total number of negative images\n",
    "        verification = np.sum(np.array(results) > detection_threshold) / 4031\n",
    "        verified = np.sum(np.array(results)) > verification_threshold\n",
    "\n",
    "        return results, verified\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Input image {input_img_path} not found.\")\n",
    "        return results, False\n",
    "\n",
    "# Run verification again with adjusted thresholds\n",
    "verification_results, verified = verify(siamese_model, 0.6, a)#<= you have to update this 0.4 according to the \n",
    "# below\n",
    "\n",
    "if verified:\n",
    "    print(\"Verified\")\n",
    "else:\n",
    "    print(\"Not Verified\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
